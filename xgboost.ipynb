{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-01T12:56:52.645267Z",
     "start_time": "2024-01-01T12:56:52.620542Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from graphviz import Digraph\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#读取数据\n",
    "data = pd.read_csv('winequality-red.csv',sep=';')\n",
    "data['y'] = data['quality'].apply(lambda x:1 if x>=7 else 0)\n",
    "data = data.drop('quality',axis=1)\n",
    "X = data.drop('y',axis=1)\n",
    "Y = data['y']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T12:56:52.672318100Z",
     "start_time": "2024-01-01T12:56:52.651394800Z"
    }
   },
   "id": "3fd3f620f7229088",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#以0.8的比例划分训练集和测试集且不使用sklearn的train_test_split\n",
    "def train_test_split(X,Y,test_size=0.2):\n",
    "    np.random.seed(1)\n",
    "    shuffle_index = np.random.permutation(len(X))\n",
    "    test_size = int(len(X)*test_size)\n",
    "    test_index = shuffle_index[:test_size]\n",
    "    train_index = shuffle_index[test_size:]\n",
    "    X_train = X.iloc[train_index]\n",
    "    Y_train = Y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    Y_test = Y.iloc[test_index]\n",
    "    return X_train,Y_train,X_test,Y_test\n",
    "\n",
    "X_train,Y_train,X_test,Y_test = train_test_split(X,Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T12:56:52.703509100Z",
     "start_time": "2024-01-01T12:56:52.678545800Z"
    }
   },
   "id": "675b6f0001e959b9",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#定义XGB类\n",
    "#该XGB类通过递归的方式构造XGB中的Cart树，分裂的依据是分裂后的增益最大\n",
    "class XGB:\n",
    "\n",
    "    def __init__(self,\n",
    "                 base_score=0.5,\n",
    "                 max_depth=3,\n",
    "                 n_estimators=10,\n",
    "                 learning_rate=0.1,\n",
    "                 reg_lambda=1,\n",
    "                 gamma=0,\n",
    "                 min_child_sample=None,\n",
    "                 min_child_weight=1,\n",
    "                 objective='linear'):\n",
    "\n",
    "        self.base_score = base_score  # 最开始时给叶子节点权重所赋的值，默认0.5，\n",
    "        self.max_depth = max_depth  # 最大数深度\n",
    "        self.n_estimators = n_estimators  # 树的个数\n",
    "        self.learning_rate = learning_rate  # 学习率，这里是每棵树要乘以的权重系数\n",
    "        self.reg_lambda = reg_lambda  # L2正则项的权重系数\n",
    "        self.gamma = gamma  # 正则项中，叶子节点数T的权重系数\n",
    "        self.min_child_sample = min_child_sample  # 每个叶子节点的样本数（自己加的）\n",
    "        self.min_child_weight = min_child_weight  # 每个叶子节点的Hessian矩阵和，下面代码会细讲\n",
    "        self.objective = objective  # 目标函数，可选linear和logistic\n",
    "        self.tree_structure = {}  # 用一个字典来存储每一颗树的树结构\n",
    "\n",
    "    def xgb_cart_tree(self, X, w, m_dpth):\n",
    "        '''\n",
    "        递归的方式构造XGB中的Cart树\n",
    "        X：训练数据集\n",
    "        w：每个样本的权重值，递归赋值\n",
    "        m_dpth：树的深度\n",
    "        '''\n",
    "\n",
    "        # 边界条件：递归到指定最大深度后，跳出\n",
    "        if m_dpth > self.max_depth:\n",
    "            return\n",
    "\n",
    "        best_var, best_cut = None, None\n",
    "        # 这里增益的初值一定要设置为0，相当于对树做剪枝，即如果算出的增益小于0则不做分裂\n",
    "        max_gain = 0\n",
    "        G_left_best, G_right_best, H_left_best, H_right_best = 0, 0, 0, 0\n",
    "        # 遍历每个变量的每个切点，寻找分裂增益gain最大的切点并记录下来\n",
    "        for item in [x for x in X.columns if x not in ['g', 'h', 'y']]:\n",
    "            for cut in list(set(X[item])):\n",
    "\n",
    "                # 这里如果指定了min_child_sample则限制分裂后叶子节点的样本数都不能小于指定值\n",
    "                if self.min_child_sample:\n",
    "                    if (X.loc[X[item] < cut].shape[0] < self.min_child_sample) \\\n",
    "                            | (X.loc[X[item] >= cut].shape[0] < self.min_child_sample):\n",
    "                        continue\n",
    "\n",
    "                G_left = X.loc[X[item] < cut, 'g'].sum()\n",
    "                G_right = X.loc[X[item] >= cut, 'g'].sum()\n",
    "                H_left = X.loc[X[item] < cut, 'h'].sum()\n",
    "                H_right = X.loc[X[item] >= cut, 'h'].sum()\n",
    "\n",
    "                # min_child_weight在这里起作用，指的是每个叶子节点上的H，即目标函数二阶导的加和\n",
    "                # 当目标函数为linear，即1/2*(y-y_hat)**2时，它的二阶导是1，那min_child_weight就等价于min_child_sample\n",
    "                # 当目标函数为logistic，其二阶导为sigmoid(y_hat)*(1-sigmoid(y_hat))，可理解为叶子节点的纯度\n",
    "                if self.min_child_weight:\n",
    "                    if (H_left < self.min_child_weight) | (H_right < self.min_child_weight):\n",
    "                        continue\n",
    "\n",
    "                gain = G_left ** 2 / (H_left + self.reg_lambda) + \\\n",
    "                       G_right ** 2 / (H_right + self.reg_lambda) - \\\n",
    "                       (G_left + G_right) ** 2 / (H_left + H_right + self.reg_lambda)\n",
    "                gain = gain / 2 - self.gamma\n",
    "                if gain > max_gain:\n",
    "                    best_var, best_cut = item, cut\n",
    "                    max_gain = gain\n",
    "                    G_left_best, G_right_best, H_left_best, H_right_best = G_left, G_right, H_left, H_right\n",
    "\n",
    "        # 如果遍历完找不到可分列的点，则返回None\n",
    "        if best_var is None:\n",
    "            return None\n",
    "\n",
    "        # 给每个叶子节点上的样本分别赋上相应的权重值\n",
    "        id_left = X.loc[X[best_var] < best_cut].index.tolist()\n",
    "        w_left = - G_left_best / (H_left_best + self.reg_lambda)\n",
    "\n",
    "        id_right = X.loc[X[best_var] >= best_cut].index.tolist()\n",
    "        w_right = - G_right_best / (H_right_best + self.reg_lambda)\n",
    "\n",
    "        w[id_left] = int(w_left)\n",
    "        w[id_right] =int(w_right)\n",
    "\n",
    "        # 把树的结构给存下来\n",
    "        tree_structure = {(best_var, best_cut): {}}\n",
    "        tree_structure[(best_var, best_cut)][('left', w_left)] = self.xgb_cart_tree(X.loc[id_left], w, m_dpth + 1)\n",
    "        tree_structure[(best_var, best_cut)][('right', w_right)] = self.xgb_cart_tree(X.loc[id_right], w, m_dpth + 1)\n",
    "\n",
    "        return tree_structure\n",
    "\n",
    "    def _grad(self, y_hat, Y):\n",
    "        '''\n",
    "        计算目标函数的一阶导\n",
    "        '''\n",
    "\n",
    "        if self.objective == 'logistic':\n",
    "            y_hat = 1.0 / (1.0 + np.exp(-y_hat))\n",
    "            return y_hat - Y\n",
    "        elif self.objective == 'linear':\n",
    "            return y_hat - Y\n",
    "        else:\n",
    "            raise KeyError('objective must be linear or logistic!')\n",
    "\n",
    "    def _hess(self, y_hat, Y):\n",
    "        '''\n",
    "        计算目标函数的二阶导\n",
    "        '''\n",
    "\n",
    "        if self.objective == 'logistic':\n",
    "            y_hat = 1.0 / (1.0 + np.exp(-y_hat))\n",
    "            return y_hat * (1.0 - y_hat)\n",
    "        elif self.objective == 'linear':\n",
    "            return np.array([1] * Y.shape[0])\n",
    "        else:\n",
    "            raise KeyError('objective must be linear or logistic!')\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, Y):\n",
    "        '''\n",
    "        根据训练数据集X和Y训练出树结构和权重\n",
    "        '''\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError('X and Y must have the same length!')\n",
    "\n",
    "        X = X.reset_index(drop='True')\n",
    "        Y = Y.values\n",
    "        # 这里根据base_score参数设定权重初始值\n",
    "        y_hat = np.array([self.base_score] * Y.shape[0])\n",
    "        for t in range(self.n_estimators):\n",
    "            print('fitting tree {}...'.format(t + 1))\n",
    "\n",
    "            X['g'] = self._grad(y_hat, Y)\n",
    "            X['h'] = self._hess(y_hat, Y)\n",
    "\n",
    "            f_t = pd.Series([0] * Y.shape[0])\n",
    "            self.tree_structure[t + 1] = self.xgb_cart_tree(X, f_t, 1)\n",
    "\n",
    "            y_hat = y_hat + self.learning_rate * f_t\n",
    "\n",
    "            print('tree {} fit done!'.format(t + 1))\n",
    "\n",
    "        print(self.tree_structure)\n",
    "\n",
    "    def _get_tree_node_w(self, X, tree, w):\n",
    "        '''\n",
    "        以递归的方法，把树结构解构出来，把权重值赋到w上面\n",
    "        '''\n",
    "\n",
    "        if not tree is None:\n",
    "            k = list(tree.keys())[0]\n",
    "            var, cut = k[0], k[1]\n",
    "            X_left = X.loc[X[var] < cut]\n",
    "            id_left = X_left.index.tolist()\n",
    "            X_right = X.loc[X[var] >= cut]\n",
    "            id_right = X_right.index.tolist()\n",
    "            for kk in tree[k].keys():\n",
    "                if kk[0] == 'left':\n",
    "                    tree_left = tree[k][kk]\n",
    "                    w[id_left] = int(kk[1])\n",
    "                elif kk[0] == 'right':\n",
    "                    tree_right = tree[k][kk]\n",
    "                    w[id_right] = int(kk[1])\n",
    "\n",
    "            self._get_tree_node_w(X_left, tree_left, w)\n",
    "            self._get_tree_node_w(X_right, tree_right, w)\n",
    "\n",
    "    def predict_raw(self, X: pd.DataFrame):\n",
    "        '''\n",
    "        根据训练结果预测\n",
    "        返回原始预测值\n",
    "        '''\n",
    "\n",
    "        X = X.reset_index(drop='True')\n",
    "        Y = pd.Series([self.base_score] * X.shape[0])\n",
    "\n",
    "        for t in range(self.n_estimators):\n",
    "            tree = self.tree_structure[t + 1]\n",
    "            y_t = pd.Series([0] * X.shape[0])\n",
    "            self._get_tree_node_w(X, tree, y_t)\n",
    "            Y = Y + self.learning_rate * y_t\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def predict_prob(self, X: pd.DataFrame):\n",
    "        '''\n",
    "        当指定objective为logistic时，输出概率要做一个logistic转换\n",
    "        '''\n",
    "\n",
    "        Y = self.predict_raw(X)\n",
    "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        Y = Y.apply(sigmoid)\n",
    "        return Y\n",
    "    #利用graphviz的Digraph和递归的方法绘制树结构，id为树的编号\n",
    "    def plot_decision_tree(self,id=1):\n",
    "        tree = self.tree_structure[id]\n",
    "        dot = Digraph(comment='The Decision Tree')\n",
    "        dot.node('root', 'root')\n",
    "        self._plot_decision_tree(tree, dot, 'root')\n",
    "        graph = pydotplus.graph_from_dot_data(dot.source)\n",
    "        #显示第id棵树\n",
    "        graph.write_png('tree{}.png'.format(id))\n",
    "        dot.view()\n",
    "        \n",
    "    def _plot_decision_tree(self, tree, dot, root):\n",
    "        if not tree is None:\n",
    "            k = list(tree.keys())[0]\n",
    "            var, cut = k[0], k[1]\n",
    "            dot.node(str(k), str(k))\n",
    "            dot.edge(root, str(k))\n",
    "            for kk in tree[k].keys():\n",
    "                if kk[0] == 'left':\n",
    "                    tree_left = tree[k][kk]\n",
    "                    dot.node(str(kk), str(kk))\n",
    "                    dot.edge(str(k), str(kk))\n",
    "                elif kk[0] == 'right':\n",
    "                    tree_right = tree[k][kk]\n",
    "                    dot.node(str(kk), str(kk))\n",
    "                    dot.edge(str(k), str(kk))\n",
    "                    #随机设定颜色\n",
    "            color = lambda: np.random.randint(0, 255)#随机生成0-255的整数\n",
    "            dot.node(str(k), str(k), color='#%02X%02X%02X' % (color(), color(), color()))\n",
    "               #设置节点颜色   \n",
    "            self._plot_decision_tree(tree_left, dot, str(kk))\n",
    "            self._plot_decision_tree(tree_right, dot, str(kk))\n",
    "            \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T12:56:52.750088500Z",
     "start_time": "2024-01-01T12:56:52.717024100Z"
    }
   },
   "id": "671c6c09c47fcd93",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting tree 1...\n",
      "tree 1 fit done!\n",
      "fitting tree 2...\n",
      "tree 2 fit done!\n",
      "fitting tree 3...\n",
      "tree 3 fit done!\n",
      "fitting tree 4...\n",
      "tree 4 fit done!\n",
      "fitting tree 5...\n",
      "tree 5 fit done!\n",
      "fitting tree 6...\n",
      "tree 6 fit done!\n",
      "fitting tree 7...\n",
      "tree 7 fit done!\n",
      "fitting tree 8...\n",
      "tree 8 fit done!\n",
      "fitting tree 9...\n",
      "tree 9 fit done!\n",
      "fitting tree 10...\n",
      "tree 10 fit done!\n",
      "{1: {('alcohol', 11.6): {('left', -2.2909830213514586): {('volatile acidity', 0.38): {('left', -1.4127097872540055): {('alcohol', 10.8): {('left', -1.8659916474824116): None, ('right', -0.636045944519598): None}}, ('right', -2.4567994491235345): {('citric acid', 0.66): {('left', -2.475998944621841): None, ('right', -1.454557443653714): None}}}}, ('right', -0.6319801445823873): {('sulphates', 0.69): {('left', -1.4596083599364902): {('pH', 3.28): {('left', -0.5190200467582458): None, ('right', -1.9238769774663032): None}}, ('right', 0.32029121839964936): {('free sulfur dioxide', 19.0): {('left', 0.8721833696862978): None, ('right', -0.6855985237091587): None}}}}}}, 2: {('alcohol', 11.6): {('left', -2.0409710131222583): {('volatile acidity', 0.38): {('left', -1.3346478470297483): {('pH', 3.27): {('left', -0.7323950349736703): None, ('right', -1.8358814098753389): None}}, ('right', -2.170165395793936): {('residual sugar', 5.5): {('left', -2.198285454778492): None, ('right', -1.5260849695199368): None}}}}, ('right', -0.5938799398889134): {('sulphates', 0.69): {('left', -1.3780344318907929): {('total sulfur dioxide', 16.0): {('left', -0.2837643863941482): None, ('right', -1.7211047319282053): None}}, ('right', 0.32029121839964936): {('free sulfur dioxide', 19.0): {('left', 0.8721833696862978): None, ('right', -0.6855985237091587): None}}}}}}, 3: {('alcohol', 11.6): {('left', -1.8343347827666563): {('volatile acidity', 0.32): {('left', -0.9993433128091126): {('fixed acidity', 11.8): {('left', -1.2475418885098066): None, ('right', 0.6460044104845984): None}}, ('right', -1.9038826518810295): {('alcohol', 9.9): {('left', -2.094436861288105): None, ('right', -1.7112168705998732): None}}}}, ('right', -0.5506187923457622): {('sulphates', 0.69): {('left', -1.2882943632056805): {('pH', 3.28): {('left', -0.46231201635173974): None, ('right', -1.6870268437583305): None}}, ('right', 0.32029121839964936): {('free sulfur dioxide', 19.0): {('left', 0.8721833696862978): None, ('right', -0.6855985237091587): None}}}}}}, 4: {('alcohol', 11.6): {('left', -1.6839786121433091): {('volatile acidity', 0.34): {('left', -0.9973430401626288): {('fixed acidity', 11.6): {('left', -1.228154597469502): None, ('right', 0.6060234520175218): None}}, ('right', -1.7609678751354483): {('alcohol', 10.5): {('left', -1.8550920051025441): None, ('right', -1.5237897432552812): None}}}}, ('right', -0.5140211419974805): {('sulphates', 0.69): {('left', -1.2153782069028263): {('total sulfur dioxide', 16.0): {('left', -0.24735169940086776): None, ('right', -1.513284993242544): None}}, ('right', 0.32029121839964936): {('free sulfur dioxide', 19.0): {('left', 0.8721833696862978): None, ('right', -0.6855985237091587): None}}}}}}, 5: {('alcohol', 11.6): {('left', -1.5891744156229526): {('volatile acidity', 0.38): {('left', -1.043441007313587): {('alcohol', 10.5): {('left', -1.5611108734157735): None, ('right', -0.5162169090274082): None}}, ('right', -1.6911572526229968): {('citric acid', 0.66): {('left', -1.7067919570899723): None, ('right', -0.9343944882109633): None}}}}, ('right', -0.47242223031185643): {('sulphates', 0.62): {('left', -1.426872570791963): {('free sulfur dioxide', 32.0): {('left', -1.6347105922915708): None, ('right', 0.3961086935906341): None}}, ('right', 0.08596534264176191): {('free sulfur dioxide', 14.0): {('left', 0.5338011490027913): None, ('right', -0.4631146891276432): None}}}}}}, 6: {('alcohol', 11.6): {('left', -1.5117953930205128): {('volatile acidity', 0.34): {('left', -0.8512709678225762): {('fixed acidity', 11.6): {('left', -1.0689889569101307): None, ('right', 0.6455063229331278): None}}, ('right', -1.5882457765225975): {('alcohol', 10.5): {('left', -1.6850329919989822): None, ('right', -1.349175129440212): None}}}}, ('right', -0.4395943620421339): {('sulphates', 0.69): {('left', -1.072007300921186): {('free sulfur dioxide', 32.0): {('left', -1.2112386621279272): None, ('right', 0.50695853492976): None}}, ('right', 0.32029121839964936): {('free sulfur dioxide', 19.0): {('left', 0.8721833696862978): None, ('right', -0.6855985237091587): None}}}}}}, 7: {('alcohol', 11.6): {('left', -1.430123964323946): {('volatile acidity', 0.38): {('left', -0.9008126479095346): {('chlorides', 0.076): {('left', -0.3537843849941879): None, ('right', -1.3600437594993267): None}}, ('right', -1.5324928921271532): {('residual sugar', 5.6): {('left', -1.5538412152527128): None, ('right', -0.9673136667107544): None}}}}, ('right', -0.3892760603224656): {('sulphates', 0.62): {('left', -1.2439040095405864): {('free sulfur dioxide', 32.0): {('left', -1.4314139308403806): None, ('right', 0.3961086935906341): None}}, ('right', 0.11262710364187191): {('free sulfur dioxide', 14.0): {('left', 0.5617478056722797): None, ('right', -0.44159857747262654): None}}}}}}, 8: {('alcohol', 11.6): {('left', -1.3638576651405112): {('volatile acidity', 0.38): {('left', -0.8503033919211663): {('alcohol', 10.8): {('left', -1.2114826271922645): None, ('right', -0.2502316285051451): None}}, ('right', -1.4650370957039136): {('fixed acidity', 11.6): {('left', -1.489976440644933): None, ('right', -0.9928353295061193): None}}}}, ('right', -0.35775068046689507): {('sulphates', 0.69): {('left', -0.9214269788029761): {('total sulfur dioxide', 16.0): {('left', -0.049099754580607675): None, ('right', -1.2040940185467082): None}}, ('right', 0.32029121839964936): {('free sulfur dioxide', 19.0): {('left', 0.8721833696862978): None, ('right', -0.6855985237091587): None}}}}}}, 9: {('alcohol', 11.6): {('left', -1.301525404827928): {('volatile acidity', 0.38): {('left', -0.7940339552665302): {('pH', 3.27): {('left', -0.2859726519918909): None, ('right', -1.232183248391235): None}}, ('right', -1.403556453403293): {('alcohol', 9.9): {('left', -1.523731554588538): None, ('right', -1.2738678125729312): None}}}}, ('right', -0.31891409744820803): {('sulphates', 0.62): {('left', -1.0950749558823956): {('free sulfur dioxide', 32.0): {('left', -1.2805708300378154): None, ('right', 0.4569103752393193): None}}, ('right', 0.1322758713170405): {('free sulfur dioxide', 14.0): {('left', 0.5774818993303233): None, ('right', -0.4188477007753096): None}}}}}}, 10: {('alcohol', 10.8): {('left', -1.352809103145871): {('fixed acidity', 11.6): {('left', -1.3988730510860268): {('chlorides', 0.067): {('left', -1.0002190724602344): None, ('right', -1.4418471417594731): None}}, ('right', -0.6466194824169812): {('sulphates', 0.68): {('left', -1.286375126510642): None, ('right', 0.06462813011124344): None}}}}, ('right', -0.6082327356989252): {('sulphates', 0.69): {('left', -0.9970576769503008): {('volatile acidity', 0.4): {('left', -0.4771121912706398): None, ('right', -1.2196313639492407): None}}, ('right', -0.12057218369085691): {('total sulfur dioxide', 46.0): {('left', 0.23552484129527373): None, ('right', -0.7766545225176569): None}}}}}}}\n",
      "0      0.331812\n",
      "1      0.331812\n",
      "2      0.524979\n",
      "3      0.331812\n",
      "4      0.401312\n",
      "         ...   \n",
      "314    0.331812\n",
      "315    0.401312\n",
      "316    0.331812\n",
      "317    0.310026\n",
      "318    0.354344\n",
      "Length: 319, dtype: float64\n",
      "0     -0.7\n",
      "1     -0.7\n",
      "2      0.1\n",
      "3     -0.7\n",
      "4     -0.4\n",
      "      ... \n",
      "314   -0.7\n",
      "315   -0.4\n",
      "316   -0.7\n",
      "317   -0.8\n",
      "318   -0.6\n",
      "Length: 319, dtype: float64\n",
      "0.8808777429467085\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "xgb = XGB(max_depth=3,learning_rate=0.1,n_estimators=10,objective='logistic')\n",
    "xgb.fit(X_train,Y_train)\n",
    "#预测\n",
    "Y_pred = xgb.predict_prob(X_test)\n",
    "print(Y_pred)\n",
    "Y_pred1=xgb.predict_raw(X_test)\n",
    "print(Y_pred1)\n",
    "#把Y_pred数据类型转换为numpy.ndarray\n",
    "Y_pred=np.array(Y_pred)\n",
    "Y_test=np.array(Y_test)\n",
    "#把概率转换为0和1\n",
    "Y_pred[Y_pred>=0.5]=1\n",
    "Y_pred[Y_pred<0.5]=0\n",
    "#计算预测准确率\n",
    "prob = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i]==Y_test[i]:\n",
    "        prob+=1\n",
    "\n",
    "print(prob/len(Y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T12:57:35.830651700Z",
     "start_time": "2024-01-01T12:56:52.742128400Z"
    }
   },
   "id": "f14bad0e6f346c0f",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#绘制树结构\n",
    "xgb.plot_decision_tree(1)\n",
    "xgb.plot_decision_tree(5)\n",
    "xgb.plot_decision_tree(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T12:57:37.833138200Z",
     "start_time": "2024-01-01T12:57:35.833648800Z"
    }
   },
   "id": "893aeba9b8ac27c6",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#利用xgboost库训练模型\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463af98aa901329d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "#读取数据\n",
    "data = pd.read_csv('winequality-red.csv',sep=';')\n",
    "data['y'] = data['quality'].apply(lambda x:1 if x>=7 else 0)\n",
    "data = data.drop('quality',axis=1)\n",
    "X = data.drop('y',axis=1)\n",
    "Y = data['y']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b06f09356dbb62d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "#以0.8的比例划分训练集和测试集\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "#利用sklearn的decisiontreeclassifier作为xgboost的基分类器\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e48910c62299292"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
